{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, Sequential, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(path):\n",
    "    files=listdir(path)\n",
    "    data=[]\n",
    "    stemmer=PorterStemmer()\n",
    "    translator = str.maketrans('','' , string.punctuation)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for file in files:\n",
    "        review_updated=[]\n",
    "        file1=open(path+file,encoding=\"utf8\")\n",
    "        review=file1.read()\n",
    "        review=review.lower()\n",
    "        words = nltk.word_tokenize(review)\n",
    "        for w in words:\n",
    "            x = w.translate(translator)\n",
    "            if (x not in stop_words and x != '') :\n",
    "                stem_word=stemmer.stem(x)\n",
    "                review_updated.append(stem_word)\n",
    "        data.append(review_updated)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1=open(\"./aclImdb/imdb.vocab\",encoding=\"utf8\")\n",
    "vocab=file1.read()\n",
    "vocab = vocab.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_data=data_preprocess('./aclImdb/train/pos/')\n",
    "train_neg_data=data_preprocess('./aclImdb/train/neg/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bromwel', 'high', 'cartoon', 'comedi', 'ran', 'time', 'program', 'school', 'life', 'teacher', '35', 'year', 'teach', 'profess', 'lead', 'believ', 'bromwel', 'high', 'satir', 'much', 'closer', 'realiti', 'teacher', 'scrambl', 'surviv', 'financi', 'insight', 'student', 'see', 'right', 'pathet', 'teacher', 'pomp', 'petti', 'whole', 'situat', 'remind', 'school', 'knew', 'student', 'saw', 'episod', 'student', 'repeatedli', 'tri', 'burn', 'school', 'immedi', 'recal', 'high', 'classic', 'line', 'inspector', 'sack', 'one', 'teacher', 'student', 'welcom', 'bromwel', 'high', 'expect', 'mani', 'adult', 'age', 'think', 'bromwel', 'high', 'far', 'fetch', 'piti', 'nt']\n"
     ]
    }
   ],
   "source": [
    "print(((train_pos_data[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_df = pd.DataFrame(train_pos_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_df = pd.DataFrame({'Review': [row for row in train_pos_data]})\n",
    "train_pos_df['Label']=1\n",
    "\n",
    "train_neg_df = pd.DataFrame({'Review': [row for row in train_neg_data]})\n",
    "train_neg_df['Label']=0\n",
    "\n",
    "train_data = pd.concat([train_pos_df, train_neg_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=train_data.iloc[:,0]\n",
    "y_data=train_data.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_features = X_train.shape[0]\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUilding the LSTM Network\n",
    "\n",
    "lstm_nlp_model = Sequential()\n",
    "lstm_nlp_model.add(layers.Embedding(vocab_size, ev_features, input_length = X_train.shape[0]))\n",
    "lstm_nlp_model.add(layers.LSTM(128, activation='relu',return_sequences=True))\n",
    "lstm_nlp_model.add(layers.Dropout(0.2))\n",
    "lstm_nlp_model.add(layers.LSTM(128,activation='relu'))\n",
    "lstm_nlp_model.add(layers.Dropout(0.2))\n",
    "lstm_nlp_model.add(layers.Dense(32,activation='relu'))\n",
    "lstm_nlp_model.add(layers.Dropout(0.2))\n",
    "lstm_nlp_model.add(layers.Dense(1)) #add softmax maybe\n",
    "\n",
    "lstm_nlp_model.compile(loss='BinaryCrossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
